{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demandSimulate import demandSimulate\n",
    "\n",
    "xs = demandSimulate(0.2,0,1,3,n_sim = 60000,maturity= 1,P0 = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = np.sum(xs,axis = 1)\n",
    "\n",
    "\n",
    "xs = xs[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.Tensor(xs)\n",
    "train_y = torch.Tensor(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        base_covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "        self.covar_module = gpytorch.kernels.MultiDeviceKernel(\n",
    "            base_covar_module,\n",
    "            output_device=output_device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_x,\n",
    "          train_y,\n",
    "          output_device,\n",
    "          preconditioner_size,\n",
    "          n_training_iter,\n",
    "):\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood().to(output_device)\n",
    "    model = ExactGPModel(train_x, train_y, likelihood).to(output_device)\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = FullBatchLBFGS(model.parameters(), lr=0.1)\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "\n",
    "    with gpytorch.settings.max_preconditioner_size(preconditioner_size):\n",
    "\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_x)\n",
    "            loss = -mll(output, train_y)\n",
    "            return loss\n",
    "\n",
    "        loss = closure()\n",
    "        loss.backward()\n",
    "\n",
    "        for i in range(n_training_iter):\n",
    "            options = {'closure': closure, 'current_loss': loss, 'max_ls': 10}\n",
    "            loss, _, _, _, _, _, _, fail = optimizer.step(options)\n",
    "\n",
    "            print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "                i + 1, n_training_iter, loss.item(),\n",
    "                model.covar_module.module.base_kernel.lengthscale.item(),\n",
    "                model.likelihood.noise.item()\n",
    "            ))\n",
    "\n",
    "            if fail:\n",
    "                print('Convergence reached!')\n",
    "                break\n",
    "\n",
    "    print(f\"Finished training on {train_x.size(0)} data points using {1} GPUs.\")\n",
    "    return model, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MultiDeviceKernel.__init__() missing 1 required positional argument: 'device_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, likelihood \u001b[39m=\u001b[39m train(train_x, train_y,\n\u001b[1;32m      2\u001b[0m                            output_device\u001b[39m=\u001b[39;49moutput_device,\n\u001b[1;32m      3\u001b[0m                           preconditioner_size\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m                           n_training_iter\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[50], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_x, train_y, output_device, preconditioner_size, n_training_iter)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(train_x,\n\u001b[1;32m      2\u001b[0m           train_y,\n\u001b[1;32m      3\u001b[0m           output_device,\n\u001b[1;32m      4\u001b[0m           preconditioner_size,\n\u001b[1;32m      5\u001b[0m           n_training_iter,\n\u001b[1;32m      6\u001b[0m ):\n\u001b[1;32m      7\u001b[0m     likelihood \u001b[39m=\u001b[39m gpytorch\u001b[39m.\u001b[39mlikelihoods\u001b[39m.\u001b[39mGaussianLikelihood()\u001b[39m.\u001b[39mto(output_device)\n\u001b[0;32m----> 8\u001b[0m     model \u001b[39m=\u001b[39m ExactGPModel(train_x, train_y, likelihood)\u001b[39m.\u001b[39mto(output_device)\n\u001b[1;32m      9\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     10\u001b[0m     likelihood\u001b[39m.\u001b[39mtrain()\n",
      "Cell \u001b[0;32mIn[46], line 7\u001b[0m, in \u001b[0;36mExactGPModel.__init__\u001b[0;34m(self, train_x, train_y, likelihood)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_module \u001b[39m=\u001b[39m gpytorch\u001b[39m.\u001b[39mmeans\u001b[39m.\u001b[39mConstantMean()\n\u001b[1;32m      5\u001b[0m base_covar_module \u001b[39m=\u001b[39m gpytorch\u001b[39m.\u001b[39mkernels\u001b[39m.\u001b[39mScaleKernel(gpytorch\u001b[39m.\u001b[39mkernels\u001b[39m.\u001b[39mRBFKernel())\n\u001b[0;32m----> 7\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcovar_module \u001b[39m=\u001b[39m gpytorch\u001b[39m.\u001b[39;49mkernels\u001b[39m.\u001b[39;49mMultiDeviceKernel(\n\u001b[1;32m      8\u001b[0m     base_covar_module,\n\u001b[1;32m      9\u001b[0m     output_device\u001b[39m=\u001b[39;49moutput_device)\n",
      "\u001b[0;31mTypeError\u001b[0m: MultiDeviceKernel.__init__() missing 1 required positional argument: 'device_ids'"
     ]
    }
   ],
   "source": [
    "model, likelihood = train(train_x, train_y,\n",
    "                           output_device=output_device,\n",
    "                          preconditioner_size=100,\n",
    "                          n_training_iter=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energy_mike",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
